{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1.Pixel2Pixel：人像卡通化\n",
    "\n",
    "经过今天的学习，相信大家对图像翻译、风格迁移有了一定的了解啦，是不是也想自己动手来实现下呢？\n",
    "\n",
    "那么，为了满足大家动手实践的愿望，同时为了巩固大家学到的知识，我们Day 3的作业便是带大家完成一遍课程讲解过的应用--**Pixel2Pixel：人像卡通化**\n",
    "\n",
    "在本次作业中，大家需要做的是：**补齐代码，跑通训练，提交一张卡通化的成品图，动手完成自己的第一个人像卡通化的应用~**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6e3af14bf9f847ab92215753fb3b8f61a66186b538f44da78ca56627c35717b8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.1 准备工作：引入依赖 & 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.io import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1.1 数据准备：\n",
    "\n",
    "- 真人数据来自[seeprettyface](http://www.seeprettyface.com/mydataset.html)。\n",
    "- 数据预处理（详情见[photo2cartoon](https://github.com/minivision-ai/photo2cartoon)项目）。\n",
    "<div>\n",
    "  <img src='https://ai-studio-static-online.cdn.bcebos.com/c56c889827534363a8b6909d7737a1da64635ad33e1e44cb822f4c1cf1dfc689' height='1000px' width='1000px'>\n",
    "</div>\n",
    "\n",
    "- 使用[photo2cartoon](https://github.com/minivision-ai/photo2cartoon)项目生成真人数据对应的卡通数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压数据\r\n",
    "!unzip -q data/data79149/cartoon_A2B.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1.2 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练数据统计\r\n",
    "train_names = os.listdir('data/cartoon_A2B/train')\r\n",
    "print(f'训练集数据量: {len(train_names)}')\r\n",
    "\r\n",
    "# 测试数据统计\r\n",
    "test_names = os.listdir('data/cartoon_A2B/test')\r\n",
    "print(f'测试集数据量: {len(test_names)}')\r\n",
    "\r\n",
    "# 训练数据可视化\r\n",
    "imgs = []\r\n",
    "for img_name in np.random.choice(train_names, 3, replace=False):\r\n",
    "    imgs.append(cv2.imread('data/cartoon_A2B/train/'+img_name))\r\n",
    "\r\n",
    "img_show = np.vstack(imgs)[:,:,::-1]\r\n",
    "plt.figure(figsize=(10, 10))\r\n",
    "plt.imshow(img_show)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PairedData(Dataset):\r\n",
    "    def __init__(self, phase):\r\n",
    "        super(PairedData, self).__init__() \r\n",
    "        self.img_path_list = self.load_A2B_data(phase)    # 获取数据列表\r\n",
    "        self.num_samples = len(self.img_path_list)        # 数据量\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        img_A2B = cv2.imread(self.img_path_list[idx])     # 读取一组数据\r\n",
    "        img_A2B = img_A2B.astype('float32') / 127.5 - 1.  # 从0~255归一化至-1~1\r\n",
    "        img_A2B = img_A2B.transpose(2, 0, 1)              # 维度变换HWC -> CHW\r\n",
    "        img_A = img_A2B[..., :256]                        # 真人照\r\n",
    "        img_B = img_A2B[..., 256:]                        # 卡通图\r\n",
    "        return img_A, img_B\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return self.num_samples\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def load_A2B_data(phase):\r\n",
    "        assert phase in ['train', 'test'], \"phase should be set within ['train', 'test']\"\r\n",
    "        # 读取数据集，数据中每张图像包含照片和对应的卡通画。\r\n",
    "        data_path = 'data/cartoon_A2B/'+phase\r\n",
    "        return [os.path.join(data_path, x) for x in os.listdir(data_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paired_dataset_train = PairedData('train')\r\n",
    "paired_dataset_test = PairedData('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.2 第一步：搭建生成器\n",
    "\n",
    "### 1.2.1 请大家补齐空白处的代码，‘#’ 后是提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UnetGenerator(nn.Layer):\r\n",
    "    def __init__(self, input_nc=3, output_nc=3, ngf=64):\r\n",
    "        super(UnetGenerator, self).__init__()\r\n",
    "\r\n",
    "        self.down1 = nn.Conv2D(input_nc, ngf, kernel_size=4, stride=2, padding=1)\r\n",
    "        self.down2 = Downsample(ngf, ngf*2)\r\n",
    "        self.down3 = Downsample(ngf*2, ngf*4)\r\n",
    "        self.down4 = Downsample(ngf*4, ngf*8)\r\n",
    "        self.down5 = Downsample(ngf*8, ngf*8)\r\n",
    "        self.down6 = Downsample(ngf*8, ngf*8)\r\n",
    "        self.down7 = Downsample(ngf*8, ngf*8)\r\n",
    "\r\n",
    "        self.center = Downsample(ngf*8, ngf*8)\r\n",
    "\r\n",
    "        self.up7 = Upsample(ngf*8, ngf*8, use_dropout=True)\r\n",
    "        self.up6 = Upsample(ngf*8*2, ngf*8, use_dropout=True)\r\n",
    "        self.up5 = Upsample(ngf*8*2, ngf*8, use_dropout=True)\r\n",
    "        self.up4 = Upsample(ngf*8*2, ngf*8)\r\n",
    "        self.up3 = Upsample(ngf*8*2, ngf*4)\r\n",
    "        self.up2 = Upsample(ngf*4*2, ngf*2)\r\n",
    "        self.up1 = Upsample(ngf*2*2, ngf)\r\n",
    "\r\n",
    "        self.output_block = nn.Sequential(\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2DTranspose(ngf*2, output_nc, kernel_size=4, stride=2, padding=1),\r\n",
    "            nn.Tanh()\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        d1 = self.down1(x)\r\n",
    "        d2 = self.down2(d1)\r\n",
    "        d3 = self.down3(d2)\r\n",
    "        d4 = self.down4(d3)\r\n",
    "        d5 = self.down5(d4)\r\n",
    "        d6 = self.down6(d5)\r\n",
    "        d7 = self.down7(d6)\r\n",
    "        \r\n",
    "        c = self.center(d7)\r\n",
    "        \r\n",
    "        x = self.up7(c, d7)\r\n",
    "        x = self.up6(x, d6)\r\n",
    "        x = self.up5(x, d5)\r\n",
    "        x = self.up4(x, d4)\r\n",
    "        x = self.up3(x, d3)\r\n",
    "        x = self.up2(x, d2)\r\n",
    "        x = self.up1(x, d1)\r\n",
    "\r\n",
    "        x = self.output_block(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "class Downsample(nn.Layer):\r\n",
    "    # LeakyReLU => conv => batch norm\r\n",
    "    def __init__(self, in_dim, out_dim, kernel_size=4, stride=2, padding=1):\r\n",
    "        super(Downsample, self).__init__()\r\n",
    "\r\n",
    "        self.layers = nn.Sequential(\r\n",
    "           nn.LeakyReLU(0.2),                                                                 # LeakyReLU, leaky=0.2\r\n",
    "            nn.Conv2D(in_dim, out_dim, kernel_size, stride, padding, bias_attr=False),         # Conv2D\r\n",
    "            nn.BatchNorm2D(out_dim)     # BatchNorm2D\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.layers(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "class Upsample(nn.Layer):\r\n",
    "    # ReLU => deconv => batch norm => dropout\r\n",
    "    def __init__(self, in_dim, out_dim, kernel_size=4, stride=2, padding=1, use_dropout=False):\r\n",
    "        super(Upsample, self).__init__()\r\n",
    "\r\n",
    "        sequence = [\r\n",
    "            nn.ReLU(),                                                                          # ReLU\r\n",
    "            nn.Conv2DTranspose(in_dim, out_dim, kernel_size, stride, padding, bias_attr=False), # Conv2DTranspose\r\n",
    "            nn.BatchNorm2D(out_dim)                                                             # nn.BatchNorm2D\r\n",
    "        ]\r\n",
    "\r\n",
    "        if use_dropout:\r\n",
    "            sequence.append(nn.Dropout(p=0.5))\r\n",
    "\r\n",
    "        self.layers = nn.Sequential(*sequence)\r\n",
    "\r\n",
    "    def forward(self, x, skip):\r\n",
    "        x = self.layers(x)\r\n",
    "        x = paddle.concat([x, skip], axis=1)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.3 第二步：鉴别器的搭建\n",
    "\n",
    "### 2.3.1 请大家补齐空白处的代码，‘#’ 后是提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Layer):\r\n",
    "    def __init__(self, input_nc=6, ndf=64):\r\n",
    "        super(NLayerDiscriminator, self).__init__()\r\n",
    "\r\n",
    "        self.layers = nn.Sequential(\r\n",
    "            nn.Conv2D(input_nc, ndf, kernel_size=4, stride=2, padding=1), \r\n",
    "            nn.LeakyReLU(0.2),\r\n",
    "            \r\n",
    "            ConvBlock(ndf, ndf*2),\r\n",
    "            ConvBlock(ndf*2, ndf*4),\r\n",
    "            ConvBlock(ndf*4, ndf*8, stride=1),\r\n",
    "\r\n",
    "            nn.Conv2D(ndf*8, 1, kernel_size=4, stride=1, padding=1),\r\n",
    "            nn.Sigmoid()\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, input):\r\n",
    "        return self.layers(input)\r\n",
    "\r\n",
    "\r\n",
    "class ConvBlock(nn.Layer):\r\n",
    "    # conv => batch norm => LeakyReLU\r\n",
    "    def __init__(self, in_dim, out_dim, kernel_size=4, stride=2, padding=1):\r\n",
    "        super(ConvBlock, self).__init__()\r\n",
    "\r\n",
    "        self.layers = nn.Sequential(\r\n",
    "            nn.Conv2D(in_dim, out_dim, kernel_size, stride, padding, bias_attr=False),  # Conv2D\r\n",
    "            nn.BatchNorm2D(out_dim),                                                    # BatchNorm2D\r\n",
    "            nn.LeakyReLU(0.2)                                                           # LeakyReLU, leaky=0.2    \r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.layers(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator = UnetGenerator()\r\n",
    "discriminator = NLayerDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = generator(paddle.ones([1, 3, 256, 256]))\r\n",
    "print('生成器输出尺寸：', out.shape)  # 应为[1, 3, 256, 256]\r\n",
    "\r\n",
    "out = discriminator(paddle.ones([1, 6, 256, 256]))\r\n",
    "print('鉴别器输出尺寸：', out.shape)  # 应为[1, 1, 30, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 超参数\r\n",
    "LR = 1e-4\r\n",
    "BATCH_SIZE = 8\r\n",
    "EPOCHS = 100\r\n",
    "\r\n",
    "# 优化器\r\n",
    "optimizerG = paddle.optimizer.Adam(\r\n",
    "    learning_rate=LR,\r\n",
    "    parameters=generator.parameters(),\r\n",
    "    beta1=0.5,\r\n",
    "    beta2=0.999)\r\n",
    "\r\n",
    "optimizerD = paddle.optimizer.Adam(\r\n",
    "    learning_rate=LR,\r\n",
    "    parameters=discriminator.parameters(), \r\n",
    "    beta1=0.5,\r\n",
    "    beta2=0.999)\r\n",
    "    \r\n",
    "# 损失函数\r\n",
    "bce_loss = nn.BCELoss()\r\n",
    "l1_loss = nn.L1Loss()\r\n",
    "\r\n",
    "# dataloader\r\n",
    "data_loader_train = DataLoader(\r\n",
    "    paired_dataset_train,\r\n",
    "    batch_size=BATCH_SIZE,\r\n",
    "    shuffle=True,\r\n",
    "    drop_last=True\r\n",
    "    )\r\n",
    "\r\n",
    "data_loader_test = DataLoader(\r\n",
    "    paired_dataset_test,\r\n",
    "    batch_size=BATCH_SIZE\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_save_path = 'work/results'\r\n",
    "os.makedirs(results_save_path, exist_ok=True)  # 保存每个epoch的测试结果\r\n",
    "\r\n",
    "weights_save_path = 'work/weights'\r\n",
    "os.makedirs(weights_save_path, exist_ok=True)  # 保存模型\r\n",
    "\r\n",
    "for epoch in range(EPOCHS):\r\n",
    "    for data in tqdm(data_loader_train):\r\n",
    "        real_A, real_B = data\r\n",
    "        \r\n",
    "        optimizerD.clear_grad()\r\n",
    "        # D([real_A, real_B])\r\n",
    "        real_AB = paddle.concat((real_A, real_B), 1)\r\n",
    "        d_real_predict = discriminator(real_AB)\r\n",
    "        d_real_loss = bce_loss(d_real_predict, paddle.ones_like(d_real_predict))\r\n",
    "\r\n",
    "        # D([real_A, fake_B])\r\n",
    "        fake_B = generator(real_A).detach()\r\n",
    "        fake_AB = paddle.concat((real_A, fake_B), 1)\r\n",
    "        d_fake_predict = discriminator(fake_AB)\r\n",
    "        d_fake_loss = bce_loss(d_fake_predict, paddle.zeros_like(d_fake_predict))\r\n",
    "\r\n",
    "        \r\n",
    "        # train D\r\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2.\r\n",
    "        d_loss.backward()\r\n",
    "        optimizerD.step()\r\n",
    "\r\n",
    "        optimizerG.clear_grad()\r\n",
    "        # D([real_A, fake_B])\r\n",
    "        fake_B = generator(real_A)\r\n",
    "        fake_AB = paddle.concat((real_A, fake_B), 1)\r\n",
    "        g_fake_predict = discriminator(fake_AB)\r\n",
    "        g_bce_loss = bce_loss(g_fake_predict, paddle.ones_like(g_fake_predict))\r\n",
    "        g_l1_loss = l1_loss(fake_B, real_B) * 100.\r\n",
    "        g_loss = g_bce_loss + g_l1_loss * 1. \r\n",
    "        \r\n",
    "        # train G\r\n",
    "        g_loss.backward()\r\n",
    "        optimizerG.step()\r\n",
    "\r\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}] Loss D: {d_loss.numpy()}, Loss G: {g_loss.numpy()}')\r\n",
    "\r\n",
    "    if (epoch+1) % 10 == 0:\r\n",
    "        paddle.save(generator.state_dict(), os.path.join(weights_save_path, 'epoch'+str(epoch+1).zfill(3)+'.pdparams'))\r\n",
    "\r\n",
    "        # test\r\n",
    "        generator.eval()\r\n",
    "        with paddle.no_grad():\r\n",
    "            for data in data_loader_test:\r\n",
    "                real_A, real_B = data\r\n",
    "                break\r\n",
    "\r\n",
    "            fake_B = generator(real_A)\r\n",
    "            result = paddle.concat([real_A[:3], real_B[:3], fake_B[:3]], 3)\r\n",
    "\r\n",
    "            result = result.detach().numpy().transpose(0, 2, 3, 1)\r\n",
    "            result = np.vstack(result)\r\n",
    "            result = (result * 127.5 + 127.5).astype(np.uint8)\r\n",
    "    \r\n",
    "        cv2.imwrite(os.path.join(results_save_path, 'epoch'+str(epoch+1).zfill(3)+'.png'), result)\r\n",
    "\r\n",
    "        generator.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.4 最后：用你补齐的代码试试卡通化的效果吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 为生成器加载权重\r\n",
    "last_weights_path = os.path.join(weights_save_path, sorted(os.listdir(weights_save_path))[-1])\r\n",
    "print('加载权重:', last_weights_path)\r\n",
    "\r\n",
    "model_state_dict = paddle.load(last_weights_path)\r\n",
    "generator.load_dict(model_state_dict)\r\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取数据\r\n",
    "test_names = os.listdir('data/cartoon_A2B/test')\r\n",
    "img_name = np.random.choice(test_names)\r\n",
    "img_A2B = cv2.imread('data/cartoon_A2B/test/'+img_name)\r\n",
    "img_A = img_A2B[:, :256]                                  # 真人照\r\n",
    "img_B = img_A2B[:, 256:]                                  # 卡通图\r\n",
    "\r\n",
    "g_input = img_A.astype('float32') / 127.5 - 1             # 归一化\r\n",
    "g_input = g_input[np.newaxis, ...].transpose(0, 3, 1, 2)  # NHWC -> NCHW\r\n",
    "g_input = paddle.to_tensor(g_input)                       # numpy -> tensor\r\n",
    "\r\n",
    "g_output = generator(g_input)\r\n",
    "g_output = g_output.detach().numpy()                      # tensor -> numpy\r\n",
    "g_output = g_output.transpose(0, 2, 3, 1)[0]              # NCHW -> NHWC\r\n",
    "g_output = g_output * 127.5 + 127.5                       # 反归一化\r\n",
    "g_output = g_output.astype(np.uint8)\r\n",
    "\r\n",
    "img_show = np.hstack([img_A, g_output])[:,:,::-1]\r\n",
    "plt.figure(figsize=(8, 8))\r\n",
    "plt.imshow(img_show)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2.参考资料\n",
    "\n",
    "【PaddleGAN的Github地址】:https://github.com/PaddlePaddle/PaddleGAN\n",
    "\n",
    "【PaddleGAN的Gitee地址】:https://gitee.com/PaddlePaddle/PaddleGAN\n",
    "\n",
    "【生成对抗网络七日打卡营】课程链接：https://aistudio.baidu.com/aistudio/course/introduce/16651\n",
    "\n",
    "【生成对抗网络七日打卡营】项目合集:https://aistudio.baidu.com/aistudio/projectdetail/1807841\n",
    "\n",
    "【图像分割7日打卡营常见问题汇总】\n",
    "https://aistudio.baidu.com/aistudio/projectdetail/1100155\n",
    "\n",
    "【PaddlePaddle使用教程】\n",
    "https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/guides/index_cn.html\n",
    "\n",
    "【本地安装PaddlePaddle的常见错误】\n",
    "https://aistudio.baidu.com/aistudio/projectdetail/697227\n",
    "\n",
    "【API文档】\n",
    "https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/api/index_cn.html\n",
    "\n",
    "【PaddlePaddle/hapi Github】\n",
    "https://github.com/PaddlePaddle/hapi\n",
    "\n",
    "【Github使用】\n",
    "https://guides.github.com/activities/hello-world/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3.个人介绍\n",
    "> 中南大学 机电工程学院 机械工程专业 2019级 研究生 雷钢\n",
    "\n",
    "> 百度飞桨官方帮帮团成员\n",
    "\n",
    "> Github地址：https://github.com/leigangblog\n",
    "\n",
    "> B站：https://space.bilibili.com/53420969\n",
    "\n",
    "来AI Studio互关吧，等你哦~ https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118783\n",
    "欢迎大家fork喜欢评论三连，感兴趣的朋友也可互相关注一下啊~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
